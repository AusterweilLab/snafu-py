`preprocess.py` is a script written for removing typos from `fluency_data/snafu_sample.csv` based on words from ConceptNet. The typos are replaced with the words in ConceptNet closest to them and closeness is found by Levenshtein edit distance. In case of a tie, the word found first is used. The cleaned version is in `snafu_sample_cleaned.csv`.

The files in the folder `temp` record the filtered words from conceptnet for the particular categories in SNAFU as well as a log of all the changes made to the words. Note that this is not a perfect method and all the changes are not as desired. However, this should do a good enough job for people wanting to use the data only for a general exploration or analysis. For more information, please go through the very small code in `preprocess.py` which also has instructions for installation of required packages.
